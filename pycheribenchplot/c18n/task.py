import gzip
import re
import typing as ty
from dataclasses import dataclass, field
from pathlib import Path

import cxxfilt
import networkx as nx
import numpy as np
import pandas as pd
import seaborn as sns

from ..core.analysis import AnalysisTask, BenchmarkAnalysisTask
from ..core.artefact import (DataFrameTarget, DataRunAnalysisFileTarget, LocalFileTarget)
from ..core.config import Config, ConfigPath, validate_path_exists
from ..core.pandas_util import generalized_xs
from ..core.plot import PlotTarget, PlotTask, new_figure
from ..core.task import DataGenTask, dependency, output
from .model import C18NDomainTransitionTraceModel


@dataclass
class TraceImportConfig(Config):
    # #: install rootfs where the binaries recorded in the kdump are found
    # rootfs: ConfigPath = None
    #: kdump file to import
    kdump: ConfigPath = None


@dataclass
class PrettifyTraceConfig(Config):
    #: Compress the trace output
    compress_output: bool = True


@dataclass
class TransitionGraphConfig(Config):
    #: Drop trusted / redundant transitions
    drop_redundant: bool = True


class C18NKtraceImport(DataGenTask):
    """
    Import a ktrace file for a c18n program run.

    One trace must be available for every benchmark instance, this allows to
    import parameterized data points for later aggregation.
    """
    public = True
    task_namespace = "c18n"
    task_name = "ktrace-import"
    task_config_class = TraceImportConfig

    def run(self):
        self.logger.debug("Ingest c18n domain transition kdump: %s", self.config.kdump)
        with open(self.config.kdump, "r") as kdump:
            df = self._parse(kdump)
        df.to_csv(self.data_file.path)

    @output
    def data_file(self):
        return LocalFileTarget(self, prefix="trace", ext="csv.gz", model=C18NDomainTransitionTraceModel)

    def _parse(self, kdump: ty.IO) -> pd.DataFrame:
        line_matcher = re.compile(
            r"(?P<pid>[0-9]+)\s+(?P<binary>[\w.-]+).*RTLD:.*(?P<op>leave|enter)\s+(?P<compartment>[\w./-]+).*at\s+(?P<symbol>[\w<>-]+)\s*\(?(?P<address>[\dxabcdef]*)\)?"
        )
        data = []
        failed = 0
        for line in kdump:
            line = line.strip()
            if not line:
                continue
            m = line_matcher.match(line)
            if not m:
                failed += 1
                continue
            data.append(m.groupdict())
        if failed:
            self.logger.warn("Failed to process %d records from %s", failed, self.config.kdump)
        self.logger.info("Imported %d records from kdump %s", len(data), self.config.kdump)

        df = pd.DataFrame(data)
        # Normalize addresses
        if "address" in df.columns:
            df["address"] = df["address"].map(lambda v: int(v, base=16) if v else None)
        else:
            df["address"] = np.nan
        df.index.name = "sequence"
        df["trace_source"] = self.config.kdump.name
        return df


class LoadC18NTransitionTrace(AnalysisTask):
    """
    Helper task to load and pre-process all traces we ingested
    """
    task_namespace = "c18n"
    task_name = "load-c18n-ingested-ktrace"

    @dependency
    def data(self):
        for task in self.session.find_all_exec_tasks(C18NKtraceImport):
            yield task.data_file.get_loader()

    @output
    def all_traces(self):
        return DataFrameTarget(self, C18NDomainTransitionTraceModel)

    def run(self):
        # Merge all traces, keeping the same frame shape
        df = pd.concat([t.df.get() for t in self.data])

        self.all_traces.assign(df)


class C18NTransitionsSummary(PlotTask):
    """
    Generate a simple histogram of the top 20 most frequent domain transitions.
    """
    public = True
    task_namespace = "c18n"
    task_name = "plot-top-transitions"

    @dependency
    def data(self):
        return LoadC18NTransitionTrace(self.session, self.analysis_config, self.config)

    @output
    def hist_plot(self):
        return PlotTarget(self)

    def run_plot(self):
        df = self.data.all_traces.get()

        def demangler(v):
            if v == "<unknown>":
                return v
            try:
                return cxxfilt.demangle(v)
            except cxxfilt.InvalidName:
                return "<demangler error>"
            assert False, "Not Reached"

        df["symbol"] = df["symbol"].map(demangler)

        # Count transitions
        df = df.groupby(["compartment", "symbol", "op"]).size()
        # Prepare to pivot
        df = df.to_frame(name="count").reset_index()
        # Pivot enter/leave out
        show_df = df.reset_index().pivot(index=["compartment", "symbol"], columns="op", values="count")

        show_df["total"] = show_df["enter"] + show_df["leave"]
        show_df["% enter"] = 100 * show_df["enter"] / show_df["enter"].sum()
        show_df["% leave"] = 100 * show_df["leave"] / show_df["leave"].sum()
        show_df = show_df.sort_values(by="total", ascending=False).iloc[:20]
        # Build printable labels
        show_df["transition"] = show_df.index.map(lambda i: i[0] + ":" + i[1])

        sns.set_theme()

        with new_figure(self.hist_plot.paths()) as fig:
            ax_l, ax_r = fig.subplots(1, 2, sharey=True)
            # Absolute number of transitions on the left
            tmp = show_df.copy()
            # Reduce the scale
            tmp["enter"] /= 1000
            tmp["leave"] /= 1000
            tmp.reset_index().plot(x="transition", y=["enter", "leave"], kind="barh", ax=ax_l)
            ax_l.tick_params(axis="y", labelsize="xx-small")
            ax_l.set_xlabel("# of transitions (k)")
            # Relative number of transitions on the right
            show_df.reset_index().plot(x="transition", y=["% enter", "% leave"], kind="barh", ax=ax_r)
            ax_r.tick_params(axis="y", labelsize="xx-small")
            ax_r.set_xlabel("% of transitions")


class C18NTransitionGraph(PlotTask):
    """
    Generate a graph with relationship between compartments.
    """
    public = True
    task_namespace = "c18n"
    task_name = "plot-compartment-graph"
    task_config_class = TransitionGraphConfig

    @dependency
    def data(self):
        return LoadC18NTransitionTrace(self.session, self.analysis_config, self.config)

    @output
    def reachability_plot(self):
        return PlotTarget(self)

    def run_plot(self):
        df = self.data.all_traces.get()
        graph = nx.DiGraph()

        names = df.index.unique("binary")
        if len(names) > 1:
            self.logger.error("Multiple names for the traced binary?")
            raise RuntimeError("Unexpected Input")
        binary_name = names[0]

        # Simplify the compartment names for display
        def simplify_name(n):
            comp = Path(n).name.split(".")
            comp[0] = comp[0][3:] if comp[0].startswith("lib") else comp[0]
            name = ".".join(comp[:2])
            # XXX terrible hack, sometimes we find libc without the .so suffix
            # this ensures that they are accounted as the same thing.
            if name == "c":
                name = "c.so"
            return name

        df["compartment"] = df["compartment"].map(simplify_name)

        if self.config.drop_redundant:
            to_drop = df["compartment"].isin(["c.so", "thr.so", "ld-elf-c18n.so"])
            df = df.loc[~to_drop]

        # Need to determine the source compartment for each "enter" entry
        # while we are scanning, add entries to the graph
        self.logger.info("Computing transition graph")
        enter_stack = [binary_name]

        def fill_graph(row):
            if row["op"] == "enter":
                current = enter_stack[-1]
                enter_stack.append(row["compartment"])
                edge_id = (current, row["compartment"])

                if not edge_id in graph.edges:
                    graph.add_edge(*edge_id, weight=1)
                else:
                    e = graph.edges[*edge_id]
                    e["weight"] += 1
            else:
                enter_stack.pop()

        df.apply(fill_graph, axis=1)
        del df
        self.logger.info("Draw transition graph")

        # Self loop edges are not really interesting
        if self.config.drop_redundant:
            graph.remove_edges_from(nx.selfloop_edges(graph))

        sns.set_theme()
        cmap = sns.color_palette("flare", as_cmap=True)

        draw_options = {
            "node_color": "#a0cbe2",
            "edge_color": nx.get_edge_attributes(graph, "weight").values(),
            "edge_cmap": cmap,
            "width": 0.7,
            "font_size": 4,
            "with_labels": True,
            "node_size": 100,
            "arrowsize": 3
        }

        # layout = nx.kamada_kawai_layout(graph, weight="weight", scale=4)
        layout = nx.nx_agraph.graphviz_layout(graph, prog="neato")

        with new_figure(self.reachability_plot.paths()) as fig:
            ax = fig.subplots(1, 1)
            nx.draw(graph, pos=layout, ax=ax, **draw_options)


class C18NAnnotateTrace(BenchmarkAnalysisTask):
    """
    Annotate a single trace to make it human-readable

    This will generate an output text file with indentation
    and names demangled.
    """
    task_namespace = "c18n"
    task_name = "prettify-one-trace"
    task_config_class = PrettifyTraceConfig

    @dependency
    def data(self):
        task = self.benchmark.find_exec_task(C18NKtraceImport)
        return task.data_file.get_loader()

    @output
    def annotated(self):
        ext = "txt"
        if self.config.compress_output:
            ext += ".gz"
        return DataRunAnalysisFileTarget(self, ext=ext)

    def run(self):
        df = self.data.df.get()
        srcs = df.index.unique("trace_source")
        if len(srcs) > 1:
            self.logger.error("Multiple trace sources detected for a single datarun?")
            raise RuntimeError("Unexpected input")
        self.logger.info("Annotate trace %s", srcs[0])

        # Compute indentation depth
        df["depth"] = 1
        df["depth"] = df["depth"].mask(df["op"] == "leave", -1)
        df["depth"] = df["depth"].cumsum() - 1
        # Increase depth of leave so that they are at the same indentation level
        # of the ENTER we are leaving
        df.loc[df["op"] == "leave", "depth"] += 1

        def demangler(v):
            if v == "<unknown>":
                return v
            try:
                return cxxfilt.demangle(v)
            except cxxfilt.InvalidName:
                return v + " <DEMANGLE ERR>"
            assert False, "Not Reached"

        df["symbol"] = df["symbol"].map(demangler)
        df["address"] = df["address"].map(lambda v: f"0x{int(v):x}", na_action="ignore").fillna("")

        space = "  "
        dump = (
            df["depth"].map(lambda d: space * d) +
            (df["address"] + " " + df["op"].str.upper() + " " + df["compartment"] + ":" + df["symbol"]).str.strip() +
            "\n")

        self.logger.info("Writeback trace")

        if self.config.compress_output:
            openfn = gzip.open
        else:
            openfn = open
        with openfn(self.annotated.path, "wt") as outfile:
            outfile.writelines(dump)


class C18NTraceAnnotation(AnalysisTask):
    """
    Schedule trace annotation for all traces
    """
    public = True
    task_namespace = "c18n"
    task_name = "prettify-trace"
    task_config_class = PrettifyTraceConfig

    @dependency
    def deps(self):
        for b in self.session.all_benchmarks():
            yield C18NAnnotateTrace(b, self.analysis_config, self.config)

    def run(self):
        pass
